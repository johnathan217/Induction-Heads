Attention pattern for layer 5 (model run on repeated sequence of tokens):
<img width="509" alt="AttentionPattern" src="https://github.com/user-attachments/assets/3f0f69d4-0574-4c17-972f-c24ede27f75f">


Induction score by head for gpt2-small:    
<img width="559" alt="InductionScorePlot" src="https://github.com/user-attachments/assets/4d6287b7-c05e-4609-a88c-18ccb368b81c">


Attribution of each component to correct logit for induction task in gpt2-small:
<img width="986" alt="LogitAttributionpng" src="https://github.com/user-attachments/assets/f66e0640-8b14-4926-a052-e51b831fd189">
